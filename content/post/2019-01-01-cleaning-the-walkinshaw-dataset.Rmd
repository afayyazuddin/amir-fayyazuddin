---
title: Cleaning the Walkinshaw dataset. Part I
author: Amir Fayyazuddin
date: '2019-01-01'
slug: cleaning-the-walkinshaw-dataset-part-I
categories: []
tags: []
image:
  caption: ''
  focal_point: ''
---

In 2015, the Davis lab published a genome-wide screen of genes involved in memory using 3207 RNAi lines from the VDRC collection [(Walkinshaw et al. 2015 Genetics 199(4):1173-1182)](http://www.genetics.org/content/199/4/1173). They generously published the their entire primary dataset including the scores for the lines that didn't show an effect as well as those that did. The data is split across several tables in the paper itself as well as in the supplementary data and some of the identifiers are not standard. In this post I will document how I went about scraping the tables from the PDF of the paper and merging it with the supplementary data to generate a single table with programmatically updated identifiers. I have also provided the data cleaning script as a standalone text file. However, I don't make any guarantees as to the correctness of the final product and so you should use it with an appropriate level of caution.

The [paper](http://www.genetics.org/content/genetics/199/4/1173.full.pdf) itself is available for free download from the Genetics website. I saved my copy as Walkinshaw2015.pdf in a directory called Walkinshaw_data in my project directory but you can store it anywhere that is convenient and just remember to write out the appropriate paths. From this document we will scrape data from two tables: 1. Table 2 contains genes whose disruption leads to an enhancement in the memory score AKA performance index (PI) and which were confirmed in a secondary screen, 2. Supplementary Table S2 lists the genes whose knock-down caused a decrease in the PI. The `tabulizer` package from rOpenSci makes it very easy to perform this task by providing a convenient API to the Java Tabula package for extracting tables from PDFs. 

The following code snippet extracts the table on page 5 of the PDF.

```{r} 
library(tabulizer)
increasedPI <- tabulizer::extract_tables("Walkinshaw_data/Walkinshaw2015.pdf",
                                         pages=5) 
```

The output of the **extract_tables()** command is a list of character matrices where each matrix contains the data from one page of the table. Since Table 2 is entirely contained within one page we can check its formatting by printing the first few rows of the first (and only) element of the list.  
```{r}

head(increasedPI[[1]], 10)

```

There are a few things that are immediately obvious that need to be corrected:

1. Information that should be restricted to one row is sometimes spread out over two rows. For example the column names are in rows 1 and 2.
3. Full gene names are used instead of standardized gene symbols.
4. The symbol for +/- is somehow converted to the number 6.
5. The PI and SEM should be in separate columns.
6. The PI and SEM are coded as character data types and should be numeric.
7. Absence of physical abnormality is coded by a non-standard character instead of "-".

We will wait to correct these issues until we have added the data for lines that showed a decrease in the memory score from Supplemental Table S2. In the meantime we will convert this table to a dataframe and add a column that indicates the sign of the change in memory relative to wildtype.

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
df_increasedPI <- 
  # convert to dataframe
  as_data_frame(increasedPI[[1]]) %>% 
  # Remove rows containing column names
  slice(-1:-2) %>%
  # Add proper column names
  rename(vdrc_id=1, cg_number=2, gene_name=3, primary_score=4, 
         secondary_score=5, physical_abnormality=6, 
         mean_activity_difference=7, act_sig=8) %>% 
  mutate(change_in_memory = "+")

```
Next we repeat this process with Supplementary Table S2 which contains the data for lines where disrupting the gene product causes a reduction in the memory score or PI. We again use the `tabulizer` package to read in the data but this time it is spread over several pages (pp. 13-38) of the Extended PDF. Looking at the first 10 rows of the first matrix of the output we notice that there are 18 columns, some of which have no elements.

```{r, cache=TRUE}
decreasedPI <- tabulizer::extract_tables("Walkinshaw_data/Walkinshaw2015.pdf", pages=13:38)
head(decreasedPI[[1]], 10)
```
We want to make sure that all of the matrices of the output list are uniform so we use **sapply()** with the **dim()** function to check the dimensions of each of the 26 matrices in the list. Each column in the output below encodes the data from a single matrix of the list with the row and column dimensions encoded in rows 1 and 2 respectively.

```{r}
sapply(decreasedPI, dim)
```

From this output table we see that the first matrix has 18 columns but each of the other matrices have 8 columns each. We will define a custom function, **dataframe_from_list()**, that removes empty columns from each matrix using the **remove_empty_cols()** function of the `janitor` package, converts missing data to NAs, and renames the columns.

```{r}
library(janitor)
dataframe_from_list<-function(mylist){
  data.frame(mylist, stringsAsFactors = FALSE) %>%
    mutate_all(funs(na_if(.,""))) %>% 
    remove_empty("cols") %>% 
    rename(vdrc_id=1, cg_number=2, gene_name=3, primary_score=4, 
           secondary_score=5, physical_abnormality=6,
           mean_activity_difference=7,act_sig=8)
}
```
Now we use **lapply()** to apply this function to each element of the decreasedPI list of matrices and convert it to a list of dataframes. We will convert the list to a single dataframe with the **bind_rows()** function from the tidyverse `dplyr` package and add a new column called *change_in_memory* with value "-" to indicate a decrease in memory.
```{r}
df_decreasedPI<-lapply(decreasedPI, dataframe_from_list)
df_decreasedPI<-df_decreasedPI %>%
  bind_rows() %>%
  # Remove the first row containing column names
  slice(-1) %>%
  # Add column to indicate significant reduction in memory score
  mutate(change_in_memory = "-")
```
Unlike the *increasedPI* table not all cases in the *decreasedPI* table have scores for changes in activity which suggests that this test wasn't done for all lines. In our dataframe we have NAs in the *act_sig* column in all cases where there isn't a significant difference. In order to match the *df_increasedPI* table we want to change the *act_sig* column to have a null value in all cases that have a value in the mean_activity_difference column rather than an NA.
```{r}
df_decreasedPI<-df_decreasedPI %>% 
  mutate(act_sig=if_else(!is.na(mean_activity_difference), "", act_sig))

head(df_decreasedPI, 10)
```
We can now combine the two dataframes for increased and decreased scores into a single one that we will call significant_lines.
```{r}
significant_lines <- bind_rows(df_decreasedPI, df_increasedPI)

glimpse(significant_lines)
```

In the next chunk of code we will correct all of these problems using packages from the tidyverse. We will use the pipe operator **%>%** from the `tidyr` package to string together operations. What each element of the code does is commented in the code chunk below so I won't break it down further here. For the time being we will remove the gene names from the table and add in standardized symbols from a public database in the next post. 
```{r, message=FALSE, warning=FALSE}
significant_lines <- significant_lines %>% 
  # Put PI and SEM in separate columns 
  separate(primary_score, c("primary_PI", "dummy", "primary_SEM"), " ")%>%
  dplyr::select(-dummy) %>%
  separate(secondary_score, c("secondary_PI", "dummy", "secondary_SEM"), " ") %>%
  # remove +/- character and gene names
  dplyr::select(-dummy, -gene_name) %>%
  # Remove all rows that don't have a valid vdrc_id
  filter(vdrc_id != "") %>%
  # Encode physical abnormality by + or -
  mutate(physical_abnormality = replace(physical_abnormality, 
                                        physical_abnormality != "+", "-")) %>%
  # convert VDRC identifiers to integers
  mutate(vdrc_id = strtoi(vdrc_id)) %>%
  # Convert PI and SEM to numeric
  mutate(primary_PI = as.double(primary_PI), 
         primary_SEM = abs(as.double(primary_SEM))) %>%
  mutate(secondary_PI = as.double(secondary_PI), 
         secondary_SEM = abs(as.double(secondary_SEM))) %>%
  # Convert Mean Activity Difference to numeric and add column to indicate increase in memory
  mutate(mean_activity_difference = as.double(mean_activity_difference)) %>% 
  # Sort the dataframe by the VDRC identifier
  arrange(vdrc_id)
```


Now if we inspect the dataframe we see data for 599 lines and the scores are separated into separate columns.

```{r}
glimpse(significant_lines)
```

We can do some basic checks to see if our cleaned data matches the data in the publication. The paper indicates that 600 lines showed a significant change in memory scores which corresponds quite well with the 599 rows in our cleaned dataframe. Of the 600 lines 42 lines showed an increased PI. We can filter our dataframe with this information.

```{r}
significant_lines %>% 
  dplyr::filter(change_in_memory=="+") %>% 
  glimpse()
```
So our dataframe also has 42 lines that show an increased memory score matching the paper.

I have collected all of the data cleaning commands from this post in a script that is pasted below. You can source it to build the significant_lines dataframe. In the next post I will describe how to clean the supplemental table that contains the entire dataset of 3207 lines and update identifiers programmatically using the `biomaRt` package to query the Ensembl BioMart webservice.

```{r, eval=FALSE}
library(tabulizer)
library(dplyr)
library(tidyr)
library(janitor)

dataframe_from_list<-function(mylist){
  data.frame(mylist, stringsAsFactors = FALSE) %>%
    mutate_all(funs(na_if(.,""))) %>% 
    remove_empty("cols") %>% 
    rename(vdrc_id=1, cg_number=2, gene_name=3, primary_score=4, 
           secondary_score=5, physical_abnormality=6,
           mean_activity_difference=7,act_sig=8)
}
  

increasedPI <- tabulizer::extract_tables("/path/to/directory/Walkinshaw2016.pdf", 
                                         pages=5) 
# Extract Table 2 located on page 5 of the manuscript


df_increasedPI <- 
  # convert to dataframe
  as_data_frame(increasedPI[[1]]) %>% 
  # Remove rows containing column names
  slice(-1:-2) %>%
  # Add proper column names
  dataframe_from_list() %>% 
  # Add column to indicate sign of change in memory
  mutate(change_in_memory = "+")

decreasedPI <- tabulizer::extract_tables("/path/to/directory//Walkinshaw2016.pdf", 
                                         pages=13:38)

df_decreasedPI<-lapply(decreasedPI, dataframe_from_list)
df_decreasedPI<-df_decreasedPI %>%
  bind_rows() %>% 
  # Remove the first row containing column names
  slice(-1) %>%
  # Add column to indicate significant reduction in memory score
  mutate(change_in_memory = "-") %>% 
  mutate(act_sig=if_else(!is.na(mean_activity_difference), "", act_sig))
 

significant_lines <- bind_rows(df_decreasedPI, df_increasedPI) %>% 
  # Put PI and SEM in separate columns 
  separate(primary_score, c("primary_PI", "dummy", "primary_SEM"), " ")%>%
  dplyr::select(-dummy) %>%
  separate(secondary_score, c("secondary_PI", "dummy", "secondary_SEM"), " ") %>%
  # remove +/- character and gene names
  dplyr::select(-dummy, -gene_name) %>%
  # Remove all rows that don't have a valid vdrc_id
  filter(vdrc_id != "") %>%
  # Encode physical abnormality by + or -
  mutate(physical_abnormality = replace(physical_abnormality, 
                                        physical_abnormality != "+", "-")) %>%
  # convert VDRC identifiers to integers
  mutate(vdrc_id = strtoi(vdrc_id)) %>%
  # Convert PI and SEM to numeric
  mutate(primary_PI = as.double(primary_PI), 
         primary_SEM = abs(as.double(primary_SEM))) %>%
  mutate(secondary_PI = as.double(secondary_PI), 
         secondary_SEM = abs(as.double(secondary_SEM))) %>%
  # Convert Mean Activity Difference to numeric and add column to indicate increase in memory
  mutate(mean_activity_difference = as.double(mean_activity_difference)) %>% 
  # Sort the dataframe by the VDRC identifier
  arrange(vdrc_id)
```

### Session Info
```{r}
sessionInfo()
```

